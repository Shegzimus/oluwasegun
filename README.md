

# 👋 Hi there. I'm Oluwasegun (on paper) but you can call me Viktor

## 🌟 About Me
- ⚙️ **Data Engineer** skilled in building robust and scalable ETL pipelines for cloud platforms like AWS and GCP.
- 🔢 **Academic background in Mathematics & Data Science** with proven abilities in problem-solving and abstract thinking.
- 💼 **Brief career in Management & Public Health Consulting** where I delivered data-driven solutions across various industries.
- 💻 Passionate about **data pipeline development**, and **containerized workflows**.

## 🛠️ Key Skills
- **Programming Languages**: Python, SQL, PySpark, HCL.
- **Tools & Technologies**: Docker, Airflow, Terraform, AWS (S3, Glue, EC2), GCP (BigQuery, Storage, Cloud Run).
- **Strengths**: Seeing the "bigger picture", abstracting ideas and **integrating client/manager expectations into my solution design process**.

## 💡 My Design Philosophy (what you can expect)
- **Scalable and Delegable Pipelines**: I believe in designing pipelines that are easy to operate and maintain,
  so that teams can focus on creating new solutions and solving other challenges. This approach contrasts with the common
  belief that only the author can maintain their code. I strongly believe that good pipelines require little to no author intervention after deployment.
  
- **Functionality before refinement**: I believe in getting things off the ground and starting with a pipeline that works—delivering value quickly—before refining it into a more polished, future-proof version. This saves time and lets me adapt designs based on real-world feedback.
  
- **Security and Modularity as Cornerstones**: Secure and modular designs are fundamental to my work. I focus (too much sometimes) on implementing
  best practices like secret management, non-hardcoded paths, and modular structures to ensure pipelines are robust, compliant, and easy to maintain.

## 🔭 What I’m Working On
- Developing a real-time streaming pipeline using tools like Kafka and Apache Flink to process and analyze weather and finance data (OLTP stuff).
- Building pipelines with dynamic workload management capabilities using Airflow and Spark to adjust resource allocation based on data volume and complexity.
- Implementing real-time CDC pipelines using Debezium to track and stream database changes to a cloud data warehouse

## 📈 Recent Projects
- **[Fashion Image ETL Pipeline](https://github.com/Shegzimus/DE_Fashion_Product_Images)**: A modular pipeline for extracting, transforming, and loading 133,333 images and their respective metadata for hypothetical ML use.

## 📫 Connect With Me
If you think I'll be a good addition to your team, feel free to contact me using the links below and let's discuss your next solution!
- 📧 *[Email](segun.ajet@protonmail.com)*
- 💼 *[LinkedIn](https://www.linkedin.com/in/segun-ajet/)*
- 🦜 *[Book a brief meeting](https://calendar.app.google/zEJVh3RVoMRD3odn6)*

